# Methodologie:

Pour réaliser une classification efficace sur deux notre datasets distincts, "diabetes" et "healthcare", en employant une gamme d'algorithmes variés et en optimisant les performances selon les métriques F1_score, précision, rappel et accuracy, nous avons suivre cette méthodologie concise:
Premièrement nous commencons par nettoyer et préparer les datasets : traitement des valeurs manquantes, encodage des variables catégorielles, et normalisation des données numériques. Deuxièment la division de chaque dataset en ensembles d'entraînement et de test pour évaluer les performances des modèles de manière fiable. Troisièment le sélectionnement les dix algorithmes de classification suivants : Logistic Regression (LR), Artificial Neural Networks (ANN), Decision Tree (DT), AdaBoost, Random Forest (RF), Support Vector Machine (SVM), Naïve Bayes (NB), XGBoost (XGB), K-Nearest Neighbors (KNN), et Gradient Boost, ainsi qu'une approche Deep Learning plus avancée. Quatrièment pour chaque algorithme et chaque dataset, nous avons entraînez notre modèle en utilisant l'ensemble d'entraînement et nous avons appliquez une recherche d'hyperparamètres (Grid Search ou Random Search) pour chaque modèle afin d'optimiser ses performances selon les quatre métriques ciblées (F1_score, la précision, le rappel, et le ROC_AUC ). Cinquièment l’évaluation de chaque modèle sur l'ensemble de test, en calculant le F1_score, la précision, le rappel, et le ROC_AUC pour comparer objectivement leurs performances. Sixièment l’ajustement et l’affinement des modèles selon les résultats obtenus, en envisageant les techniques avancées pour améliorer encore les performances.
Cette approche structurée permet d'explorer de manière exhaustive les capacités de chaque algorithme sur notre datasets spécifiques, garantissant une comparaison équilibrée et basée sur les données pour sélectionner le ou les modèles les plus performants pour nos besoins en classification.
![image](https://github.com/user-attachments/assets/9d1c83cf-63a5-49f6-87fc-5387a30d928e)
